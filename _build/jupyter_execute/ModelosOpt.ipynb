{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **4. Algoritmos de Optimización**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los algoritmos de Machine Learning a menudo requieren técnicas de optimización para mejorar su rendimiento en términos de velocidad y consumo de memoria sin comprometer la precisión. A continuación, se presentan tres métodos populares:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Librerías Importadas\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import faiss\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "import json\n",
    "\n",
    "# Cargar datos\n",
    "df = pd.read_csv(r\"C:\\Users\\TAWTOCA\\OneDrive - Universidad del Norte\\Documentos\\Visual Folders\\Visual Files\\Rentabilidad_filtrado.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Definir variables predictoras y respuesta\n",
    "X = df[[\"APORTES_RECIBIDOS\", \"TIPO_PARTICIPACION\", \"PRECIERRE_FONDO_DIA_T\",  \"NUMERO_INVERSIONISTAS\", \"TIPO_ENTIDAD\"]]\n",
    "y = df[\"RETIROS_REDENCIONES\"]\n",
    "\n",
    "\n",
    "# Dividir en conjunto de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4.1. K-NN** `KD-Trees, Ball Trees, FAISS` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(k, algorithm, grid_search_json=\"modelos_guardados\\params\\knn_params.json\"):\n",
    "    # Si se pasa el JSON de GridSearch, se cargan los mejores parámetros\n",
    "    if grid_search_json:\n",
    "        with open(grid_search_json, 'r') as f:\n",
    "            grid_params = json.load(f)\n",
    "        \n",
    "        # Asumimos que el JSON contiene un diccionario con los mejores parámetros\n",
    "        best_params = grid_params.get('best_params', {})\n",
    "        \n",
    "        # Si los parámetros de GridSearch están disponibles, usarlos para configurar el modelo\n",
    "        if 'n_neighbors' in best_params:\n",
    "            k = best_params['n_neighbors']\n",
    "        if 'algorithm' in best_params:\n",
    "            algorithm = best_params['algorithm']\n",
    "    \n",
    "    # Crear el modelo KNN con los parámetros seleccionados\n",
    "    KNN = KNeighborsRegressor(n_neighbors=k, weights='uniform', algorithm=algorithm, leaf_size=30, n_jobs=-1)\n",
    "    \n",
    "    # Entrenamiento\n",
    "    st = time.time()\n",
    "    KNN.fit(X_train, y_train)\n",
    "    et = time.time()\n",
    "    print(f\"Tiempo de entrenamiento: {et - st:.4f} segundos\")    \n",
    "    \n",
    "    # Predicciones\n",
    "    y_train_pred = KNN.predict(X_train)\n",
    "    y_test_pred = KNN.predict(X_test)\n",
    "        \n",
    "    # Calcular R²\n",
    "    train_r2 = r2_score(y_train, y_train_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "        \n",
    "    # Imprimir resultados\n",
    "    print(f'R² en entrenamiento: {train_r2:.4f}')\n",
    "    print(f'R² en prueba: {test_r2:.4f}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los siguientes resultados muestran el impacto de las diferentes estructuras de datos en la eficiencia del entrenamiento del modelo KNN sin afectar la precisión del modelo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *4.1.1.*`KD-Trees`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de entrenamiento: 2.0552 segundos\n",
      "R² en entrenamiento: 0.7846\n",
      "R² en prueba: 0.7368\n"
     ]
    }
   ],
   "source": [
    "knn(5, 'kd_tree')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Más lento porque es eficiente solo en dimensiones bajas (~<30). A mayor dimensión, la búsqueda se vuelve casi tan costosa como la fuerza bruta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *4.1.2.*`Ball Trees`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de entrenamiento: 1.9436 segundos\n",
      "R² en entrenamiento: 0.7846\n",
      "R² en prueba: 0.7368\n"
     ]
    }
   ],
   "source": [
    "knn(5, 'ball_tree')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Más rápido que KD-Trees, lo que sugiere que se adapta mejor a la estructura de los datos, especialmente si la distribución de puntos es menos uniforme."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *4.1.3.*`FAISS`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementar Faiss KNN\n",
    "class FaissKNeighbors:\n",
    "    def __init__(self, k=5):\n",
    "        self.index = None\n",
    "        self.y = None\n",
    "        self.k = k\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        start_time = time.time()  # Iniciar cronómetro\n",
    "        self.index = faiss.IndexFlatL2(X.shape[1])  # Índice Faiss\n",
    "        self.index.add(X.astype(np.float32))  # Convertir X a float32\n",
    "        self.y = np.array(y)  # Convertir y a NumPy array\n",
    "        end_time = time.time()  # Finalizar cronómetro\n",
    "        print(f\"Tiempo de entrenamiento: {end_time - start_time:.4f} segundos\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        distances, indices = self.index.search(X.astype(np.float32), k=self.k)\n",
    "        votes = self.y[indices]\n",
    "        predictions = np.mean(votes, axis=1)  # Promedio de los vecinos (para regresión)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de entrenamiento: 0.1402 segundos\n",
      "\n",
      "R² en entrenamiento: 0.7846\n",
      "R² en prueba: 0.7368\n"
     ]
    }
   ],
   "source": [
    "knn_faiss = FaissKNeighbors(k=5)\n",
    "knn_faiss.fit(X_train, y_train)\n",
    "\n",
    "# Hacer predicciones en train y test\n",
    "y_train_pred = knn_faiss.predict(X_train)\n",
    "y_test_pred = knn_faiss.predict(X_test)\n",
    "\n",
    "# Evaluación del modelo\n",
    "print(f'\\nR² en entrenamiento: {r2_score(y_train, y_train_pred):.4f}')\n",
    "print(f'R² en prueba: {r2_score(y_test, y_test_pred):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drásticamente más rápido, ya que está optimizado para alta dimensionalidad y grandes volúmenes de datos, probablemente usando indexación eficiente y paralelización en CPU/GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FAISS es claramente la mejor opción en términos de tiempo sin pérdida de precisión. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En comparación con el rendimiento normal del Modelo KNN *(Página Anterior)* notamos que:\n",
    "\n",
    "**Tiempo de Entrenamiento:** KNN normal (1.47 s) está en un punto intermedio: más rápido que KD-Trees (1.7682 s) pero más lento que Ball Trees (1.1726 s) y muchísimo más lento que FAISS (0.0229 s).\n",
    "\n",
    "**Precisión:** \n",
    "- KNN normal: 0.7340\n",
    "\n",
    "- KD-Trees, Ball Trees y FAISS: 0.7368\n",
    "\n",
    "Aunque la diferencia es pequeña, el KNN normal tiene un ligero peor desempeño en prueba. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4.2. Ridge** `Solver = saga`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de entrenamiento Ridge: 2.8917 segundos\n",
      "Training set score: 0.72\n",
      "Test set score: 0.70\n"
     ]
    }
   ],
   "source": [
    "st = time.time()\n",
    "ridge = Ridge(solver='saga').fit(X_train, y_train)\n",
    "et = time.time()\n",
    "print(f\"Tiempo de entrenamiento Ridge: {et-st:.4f} segundos\")\n",
    "print(\"Training set score: {:.2f}\".format(ridge.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.2f}\".format(ridge.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solver ‘saga’ (2.7812 s) es mucho más lento que la versión normal (0.18 s).\n",
    "\n",
    "Esto sugiere que, aunque ‘saga’ está optimizado para grandes volúmenes de datos y características dispersas, en este caso, el tamaño o estructura de los datos podría no estar aprovechando su paralelización."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4.3. XGBoost** `tree_method='hist', early_stopping_rounds.` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:41834213630.41076\tvalidation_1-rmse:40867266278.54447\n",
      "[1]\tvalidation_0-rmse:39248929046.92715\tvalidation_1-rmse:38180506336.29671\n",
      "[2]\tvalidation_0-rmse:36957946486.98074\tvalidation_1-rmse:35828091844.70522\n",
      "[3]\tvalidation_0-rmse:35373890382.83579\tvalidation_1-rmse:34119232622.72684\n",
      "[4]\tvalidation_0-rmse:33623265140.80811\tvalidation_1-rmse:32304800417.45920\n",
      "[5]\tvalidation_0-rmse:32131709211.81150\tvalidation_1-rmse:30758066980.40246\n",
      "[6]\tvalidation_0-rmse:30840249840.31030\tvalidation_1-rmse:29450480293.29181\n",
      "[7]\tvalidation_0-rmse:29811586304.10691\tvalidation_1-rmse:28333506342.41018\n",
      "[8]\tvalidation_0-rmse:28947083823.27284\tvalidation_1-rmse:27386522304.09840\n",
      "[9]\tvalidation_0-rmse:28139295285.20079\tvalidation_1-rmse:26601730099.67011\n",
      "[10]\tvalidation_0-rmse:27593811321.58388\tvalidation_1-rmse:26001378834.91472\n",
      "[11]\tvalidation_0-rmse:27064695050.35685\tvalidation_1-rmse:25414219040.04436\n",
      "[12]\tvalidation_0-rmse:26546445132.13224\tvalidation_1-rmse:24927507176.11632\n",
      "[13]\tvalidation_0-rmse:26181884353.11839\tvalidation_1-rmse:24516760641.04486\n",
      "[14]\tvalidation_0-rmse:25909347327.74148\tvalidation_1-rmse:24223460597.75885\n",
      "[15]\tvalidation_0-rmse:25692479521.97620\tvalidation_1-rmse:23985017297.92968\n",
      "[16]\tvalidation_0-rmse:25392961074.28420\tvalidation_1-rmse:23744510122.73696\n",
      "[17]\tvalidation_0-rmse:25230616957.77484\tvalidation_1-rmse:23567404238.51586\n",
      "[18]\tvalidation_0-rmse:25076312469.89387\tvalidation_1-rmse:23420577195.27903\n",
      "[19]\tvalidation_0-rmse:24824342748.56131\tvalidation_1-rmse:23262483522.85431\n",
      "[20]\tvalidation_0-rmse:24642650193.62545\tvalidation_1-rmse:23132322729.15974\n",
      "[21]\tvalidation_0-rmse:24449535452.34967\tvalidation_1-rmse:23013954225.59563\n",
      "[22]\tvalidation_0-rmse:24367988273.41460\tvalidation_1-rmse:22938211864.66294\n",
      "[23]\tvalidation_0-rmse:24302163004.47666\tvalidation_1-rmse:22875722855.98869\n",
      "[24]\tvalidation_0-rmse:24220410725.33700\tvalidation_1-rmse:22789191541.62069\n",
      "[25]\tvalidation_0-rmse:24071370139.37780\tvalidation_1-rmse:22744613111.06769\n",
      "[26]\tvalidation_0-rmse:23978524829.75610\tvalidation_1-rmse:22690331739.98171\n",
      "[27]\tvalidation_0-rmse:23882281547.67146\tvalidation_1-rmse:22656115149.78147\n",
      "[28]\tvalidation_0-rmse:23842865899.11260\tvalidation_1-rmse:22617649272.90147\n",
      "[29]\tvalidation_0-rmse:23789635154.03864\tvalidation_1-rmse:22580539084.42487\n",
      "[30]\tvalidation_0-rmse:23680332951.38301\tvalidation_1-rmse:22563666776.95050\n",
      "[31]\tvalidation_0-rmse:23628461089.14579\tvalidation_1-rmse:22526529661.07670\n",
      "[32]\tvalidation_0-rmse:23606167572.85741\tvalidation_1-rmse:22506320833.63355\n",
      "[33]\tvalidation_0-rmse:23573654117.25291\tvalidation_1-rmse:22487589340.64248\n",
      "[34]\tvalidation_0-rmse:23531676530.16084\tvalidation_1-rmse:22467715520.88284\n",
      "[35]\tvalidation_0-rmse:23471406006.27819\tvalidation_1-rmse:22457441285.44429\n",
      "[36]\tvalidation_0-rmse:23361467442.36013\tvalidation_1-rmse:22445609957.68447\n",
      "[37]\tvalidation_0-rmse:23341926406.75026\tvalidation_1-rmse:22429626249.14872\n",
      "[38]\tvalidation_0-rmse:23294045427.01303\tvalidation_1-rmse:22428969085.21884\n",
      "[39]\tvalidation_0-rmse:23255313965.50353\tvalidation_1-rmse:22425800426.87314\n",
      "[40]\tvalidation_0-rmse:23139757395.80047\tvalidation_1-rmse:22406183654.72219\n",
      "[41]\tvalidation_0-rmse:23110337896.87424\tvalidation_1-rmse:22381972613.14299\n",
      "[42]\tvalidation_0-rmse:23070980625.80223\tvalidation_1-rmse:22373686831.56106\n",
      "[43]\tvalidation_0-rmse:23009082931.67293\tvalidation_1-rmse:22394937812.88820\n",
      "[44]\tvalidation_0-rmse:22918975228.12560\tvalidation_1-rmse:22390383955.21832\n",
      "[45]\tvalidation_0-rmse:22843281160.22437\tvalidation_1-rmse:22391629895.57636\n",
      "[46]\tvalidation_0-rmse:22789089913.52109\tvalidation_1-rmse:22379874216.57526\n",
      "[47]\tvalidation_0-rmse:22743422537.69195\tvalidation_1-rmse:22379234785.05580\n",
      "[48]\tvalidation_0-rmse:22741408882.12473\tvalidation_1-rmse:22370954236.85007\n",
      "[49]\tvalidation_0-rmse:22697240858.79439\tvalidation_1-rmse:22373500638.78109\n",
      "[50]\tvalidation_0-rmse:22668839833.30909\tvalidation_1-rmse:22377814918.94670\n",
      "[51]\tvalidation_0-rmse:22649735755.60670\tvalidation_1-rmse:22362289308.32994\n",
      "[52]\tvalidation_0-rmse:22645558478.53520\tvalidation_1-rmse:22360157282.21942\n",
      "[53]\tvalidation_0-rmse:22614803503.26257\tvalidation_1-rmse:22354081720.93637\n",
      "[54]\tvalidation_0-rmse:22528703621.17665\tvalidation_1-rmse:22340759308.33500\n",
      "[55]\tvalidation_0-rmse:22503674709.47833\tvalidation_1-rmse:22342662745.82992\n",
      "[56]\tvalidation_0-rmse:22427723632.87643\tvalidation_1-rmse:22351660011.79594\n",
      "[57]\tvalidation_0-rmse:22383928489.06312\tvalidation_1-rmse:22354627437.02782\n",
      "[58]\tvalidation_0-rmse:22364640592.08902\tvalidation_1-rmse:22351098149.64289\n",
      "[59]\tvalidation_0-rmse:22345061649.27033\tvalidation_1-rmse:22346758962.96457\n",
      "[60]\tvalidation_0-rmse:22335251830.97612\tvalidation_1-rmse:22341912243.44323\n",
      "[61]\tvalidation_0-rmse:22247205449.24361\tvalidation_1-rmse:22329773503.13810\n",
      "[62]\tvalidation_0-rmse:22232242565.48640\tvalidation_1-rmse:22328254438.83464\n",
      "[63]\tvalidation_0-rmse:22221959275.78002\tvalidation_1-rmse:22324829133.61763\n",
      "[64]\tvalidation_0-rmse:22172362236.05844\tvalidation_1-rmse:22335117088.27099\n",
      "[65]\tvalidation_0-rmse:22115756053.94395\tvalidation_1-rmse:22347644851.27699\n",
      "[66]\tvalidation_0-rmse:22092190489.65646\tvalidation_1-rmse:22336273079.17341\n",
      "[67]\tvalidation_0-rmse:22012338174.43386\tvalidation_1-rmse:22316600358.98769\n",
      "[68]\tvalidation_0-rmse:21974203392.18460\tvalidation_1-rmse:22290783355.85324\n",
      "[69]\tvalidation_0-rmse:21928570365.79045\tvalidation_1-rmse:22314974671.12941\n",
      "[70]\tvalidation_0-rmse:21915302059.64979\tvalidation_1-rmse:22312997972.35791\n",
      "[71]\tvalidation_0-rmse:21910463314.16984\tvalidation_1-rmse:22310984735.84255\n",
      "[72]\tvalidation_0-rmse:21874339825.41474\tvalidation_1-rmse:22326872133.20924\n",
      "[73]\tvalidation_0-rmse:21817422237.73529\tvalidation_1-rmse:22352515794.60552\n",
      "[74]\tvalidation_0-rmse:21778195153.07152\tvalidation_1-rmse:22364885778.85990\n",
      "[75]\tvalidation_0-rmse:21707642118.46259\tvalidation_1-rmse:22340511389.22284\n",
      "[76]\tvalidation_0-rmse:21702648303.95681\tvalidation_1-rmse:22309974242.39835\n",
      "[77]\tvalidation_0-rmse:21663621106.51705\tvalidation_1-rmse:22302120408.14220\n",
      "[78]\tvalidation_0-rmse:21668559939.61810\tvalidation_1-rmse:22286015007.02955\n",
      "[79]\tvalidation_0-rmse:21630398521.78607\tvalidation_1-rmse:22293804516.86909\n",
      "[80]\tvalidation_0-rmse:21618051211.86044\tvalidation_1-rmse:22289293747.75214\n",
      "[81]\tvalidation_0-rmse:21560548470.36719\tvalidation_1-rmse:22280232702.27740\n",
      "[82]\tvalidation_0-rmse:21541992169.45533\tvalidation_1-rmse:22287054459.60973\n",
      "[83]\tvalidation_0-rmse:21510456833.68576\tvalidation_1-rmse:22300005084.29186\n",
      "[84]\tvalidation_0-rmse:21457647058.00864\tvalidation_1-rmse:22286930834.59752\n",
      "[85]\tvalidation_0-rmse:21423204273.80816\tvalidation_1-rmse:22308540834.50408\n",
      "[86]\tvalidation_0-rmse:21376857680.43352\tvalidation_1-rmse:22303339512.74450\n",
      "[87]\tvalidation_0-rmse:21367547933.30170\tvalidation_1-rmse:22298078420.40723\n",
      "[88]\tvalidation_0-rmse:21338644762.09843\tvalidation_1-rmse:22298110747.69833\n",
      "[89]\tvalidation_0-rmse:21340516575.51936\tvalidation_1-rmse:22280423239.34163\n",
      "[90]\tvalidation_0-rmse:21326332269.75762\tvalidation_1-rmse:22268668000.73086\n",
      "[91]\tvalidation_0-rmse:21317628381.30245\tvalidation_1-rmse:22252848997.28280\n",
      "[92]\tvalidation_0-rmse:21306012880.62083\tvalidation_1-rmse:22256393103.93166\n",
      "[93]\tvalidation_0-rmse:21284826011.26267\tvalidation_1-rmse:22259245467.84828\n",
      "[94]\tvalidation_0-rmse:21282615765.03718\tvalidation_1-rmse:22243147091.29656\n",
      "[95]\tvalidation_0-rmse:21242233528.62771\tvalidation_1-rmse:22260850961.45335\n",
      "[96]\tvalidation_0-rmse:21234402313.84757\tvalidation_1-rmse:22259960050.44311\n",
      "[97]\tvalidation_0-rmse:21202588757.40636\tvalidation_1-rmse:22258638344.94874\n",
      "[98]\tvalidation_0-rmse:21173954224.30297\tvalidation_1-rmse:22264696971.13649\n",
      "[99]\tvalidation_0-rmse:21144749319.12196\tvalidation_1-rmse:22292225049.18359\n",
      "Tiempo de entrenamiento XGBoost: 4.7641 segundos\n",
      "R² en entrenamiento: 0.7746\n",
      "R² en prueba: 0.7439\n"
     ]
    }
   ],
   "source": [
    "XGB = XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=6, early_stopping_rounds=20,\n",
    "    min_child_weight=5,     # Controlar la división de nodos para evitar sobreajuste\n",
    "    subsample=0.8,          # Tomar muestras de los datos para evitar sobreajuste\n",
    "    colsample_bytree=0.8,\n",
    "    reg_lambda=1,           # Regularización L2 (evita sobreajuste)\n",
    "    tree_method='hist',     # Algoritmo optimizado para conjuntos grandes\n",
    "    eval_metric=\"rmse\",  random_state=42, n_jobs=-1)\n",
    "st= time.time()\n",
    "XGB.fit(X_train, y_train, \n",
    "            eval_set=[(X_train, y_train), (X_test, y_test)]) \n",
    "et= time.time()\n",
    "print(f\"Tiempo de entrenamiento XGBoost: {et-st:.4f} segundos\")\n",
    "\n",
    "    # Predicciones\n",
    "y_train_pred = XGB.predict(X_train)\n",
    "y_test_pred = XGB.predict(X_test)\n",
    "    \n",
    "    # Calcular R²\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "    \n",
    "    # Imprimir resultados\n",
    "print(f'R² en entrenamiento: {train_r2:.4f}')\n",
    "print(f'R² en prueba: {test_r2:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost optimizado (4.26 s) es más de 2 veces más rápido que la versión normal (9.37 s). Ligeramente menor R² en entrenamiento (0.7746), pero mejor en prueba (0.7439), lo que sugiere mejor generalización comparado con el normal."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}